{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9c5c835-1897-44ab-8758-621b65874b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "claims = pd.read_csv('claims.csv', dayfirst= True)\n",
    "rtw = pd.read_csv('return_to_work.csv')\n",
    "comp = pd.read_csv('compensation_costs.csv')\n",
    "services = pd.read_csv('services_delivered.csv')\n",
    "billing = pd.read_csv('billing_policy.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5153a57-5ae0-4ff2-a200-1d5f2152697a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Claims \n",
      "\n",
      "(3000, 6)\n",
      "    claim_id      injury_type                 injury_date  worker_age gender  \\\n",
      "0  CLM000001  Musculoskeletal  2024-05-31 20:28:56.203214          31   Male   \n",
      "1  CLM000002            Other  2025-01-12 20:28:56.203214          46   Male   \n",
      "2  CLM000003         Fracture  2022-04-22 20:28:56.203214          44   Male   \n",
      "3  CLM000004    Psychological  2024-03-05 20:28:56.203214          51   Male   \n",
      "4  CLM000005  Musculoskeletal  2023-11-29 20:28:56.203214          34   Male   \n",
      "\n",
      "  employer_id  \n",
      "0     EMP0051  \n",
      "1     EMP0270  \n",
      "2     EMP0315  \n",
      "3     EMP0083  \n",
      "4     EMP0306  \n",
      "\n",
      " RTW \n",
      "\n",
      "(3000, 5)\n",
      "    claim_id  days_off_work rtw_status company_name     job_role\n",
      "0  CLM000001            391    Partial    LogiTrans        Nurse\n",
      "1  CLM000002             46    Partial   RetailMart     Labourer\n",
      "2  CLM000003              8       Full    LogiTrans  Electrician\n",
      "3  CLM000004             27    Partial    LogiTrans     Labourer\n",
      "4  CLM000005             29    Partial   HealthPlus        Nurse\n",
      "\n",
      " Comp \n",
      "\n",
      "(3000, 6)\n",
      "    claim_id  total_income_support_paid  impairment_percentage  \\\n",
      "0  CLM000001                   82452.68                    0.0   \n",
      "1  CLM000002                    8272.96                    0.0   \n",
      "2  CLM000003                    1638.09                    0.0   \n",
      "3  CLM000004                    7699.37                    0.0   \n",
      "4  CLM000005                    5682.22                    0.0   \n",
      "\n",
      "   medical_expenses  legal_costs  return_to_work_costs  \n",
      "0           1586.47          0.0              12714.06  \n",
      "1           2603.44          0.0               1877.44  \n",
      "2           9739.93          0.0                  0.00  \n",
      "3          13751.15          0.0                  0.00  \n",
      "4           4274.73          0.0                  0.00  \n",
      "\n",
      " Services \n",
      "\n",
      "(8882, 5)\n",
      "    claim_id service_category   service_name     provider  service_cost\n",
      "0  CLM000001    Psychological    Counselling  Provider_87       4075.44\n",
      "1  CLM000002          Medical        Surgery  Provider_35       6464.45\n",
      "2  CLM000002          Medical        Surgery  Provider_50       6818.15\n",
      "3  CLM000003          Medical  Physiotherapy  Provider_68       1479.70\n",
      "4  CLM000003          Medical        Surgery  Provider_60       6125.08\n",
      "\n",
      " Billing \n",
      "\n",
      "(8882, 5)\n",
      "    claim_id  invoice_amount paid_status  days_to_pay         policy_name\n",
      "0  CLM000001         4075.44        Paid         20.0     Standard Policy\n",
      "1  CLM000002         6464.45        Paid         17.0     Standard Policy\n",
      "2  CLM000002         6818.15     Overdue         98.0     Standard Policy\n",
      "3  CLM000003         1479.70        Paid         17.0  Early Intervention\n",
      "4  CLM000003         6125.08     Overdue        117.0     Standard Policy\n"
     ]
    }
   ],
   "source": [
    "#placing all the datasets in a library and analysing basic infor such as first five rows, shape of data\n",
    "dataset = {\n",
    "    \"Claims\":claims,\n",
    "    \"RTW\" : rtw,\n",
    "    \"Comp\" : comp,\n",
    "    \"Services\" : services,\n",
    "    \"Billing\" : billing \n",
    "}\n",
    "\n",
    "for name, df in dataset.items():\n",
    "    print(f'\\n {name} \\n')\n",
    "    print(df.shape)\n",
    "    print(df.head())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2fbc5190-2f14-4808-a6f0-a8d95381d5ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        worker_age\n",
      "count  3000.000000\n",
      "mean     41.208000\n",
      "std      10.131681\n",
      "min      18.000000\n",
      "25%      34.000000\n",
      "50%      41.000000\n",
      "75%      48.000000\n",
      "max      70.000000\n",
      "       days_off_work\n",
      "count    3000.000000\n",
      "mean       45.745333\n",
      "std        42.797566\n",
      "min         1.000000\n",
      "25%        19.000000\n",
      "50%        34.000000\n",
      "75%        58.000000\n",
      "max       464.000000\n",
      "       total_income_support_paid  impairment_percentage  medical_expenses  \\\n",
      "count                3000.000000            3000.000000       3000.000000   \n",
      "mean                10828.743013               6.514133       8961.310410   \n",
      "std                 10793.449492              11.465747       9763.907296   \n",
      "min                   180.230000               0.000000        199.750000   \n",
      "25%                  4178.240000               0.000000       3283.375000   \n",
      "50%                  7532.100000               0.000000       5904.545000   \n",
      "75%                 13631.562500              10.200000      11208.077500   \n",
      "max                118264.170000              40.000000     142368.010000   \n",
      "\n",
      "        legal_costs  return_to_work_costs  \n",
      "count   3000.000000           3000.000000  \n",
      "mean    3479.841323           4366.547773  \n",
      "std    11330.961585           4941.968314  \n",
      "min        0.000000              0.000000  \n",
      "25%        0.000000              0.000000  \n",
      "50%        0.000000           2292.090000  \n",
      "75%        0.000000           8403.537500  \n",
      "max    59959.970000          14997.330000  \n",
      "       service_cost\n",
      "count   8882.000000\n",
      "mean    4406.231438\n",
      "std     2418.903351\n",
      "min      205.580000\n",
      "25%     2381.800000\n",
      "50%     4407.895000\n",
      "75%     6300.725000\n",
      "max    11962.350000\n",
      "       invoice_amount  days_to_pay\n",
      "count     8882.000000  8038.000000\n",
      "mean      4406.231438    33.918388\n",
      "std       2418.903351    24.795273\n",
      "min        205.580000   -10.000000\n",
      "25%       2381.800000    19.000000\n",
      "50%       4407.895000    27.000000\n",
      "75%       6300.725000    38.000000\n",
      "max      11962.350000   119.000000\n"
     ]
    }
   ],
   "source": [
    "#summary stats\n",
    "for name, df in dataset.items():\n",
    "    print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30c35daf-bc3d-4182-8578-fd34e334a13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Claims - Missing Value (%) \n",
      "\n",
      "claim_id       0.0\n",
      "injury_type    0.0\n",
      "injury_date    0.0\n",
      "worker_age     0.0\n",
      "gender         0.0\n",
      "employer_id    0.0\n",
      "dtype: float64\n",
      "\n",
      " RTW - Missing Value (%) \n",
      "\n",
      "claim_id         0.0\n",
      "days_off_work    0.0\n",
      "rtw_status       0.0\n",
      "company_name     0.0\n",
      "job_role         0.0\n",
      "dtype: float64\n",
      "\n",
      " Comp - Missing Value (%) \n",
      "\n",
      "claim_id                     0.0\n",
      "total_income_support_paid    0.0\n",
      "impairment_percentage        0.0\n",
      "medical_expenses             0.0\n",
      "legal_costs                  0.0\n",
      "return_to_work_costs         0.0\n",
      "dtype: float64\n",
      "\n",
      " Services - Missing Value (%) \n",
      "\n",
      "claim_id            0.0\n",
      "service_category    0.0\n",
      "service_name        0.0\n",
      "provider            0.0\n",
      "service_cost        0.0\n",
      "dtype: float64\n",
      "\n",
      " Billing - Missing Value (%) \n",
      "\n",
      "days_to_pay       0.095024\n",
      "claim_id          0.000000\n",
      "invoice_amount    0.000000\n",
      "paid_status       0.000000\n",
      "policy_name       0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#finding missing values - using mean () to find the % of missing values\n",
    "for name, df in dataset.items():\n",
    "    print(f'\\n {name} - Missing Value (%) \\n')\n",
    "    print(df.isnull().mean().sort_values(ascending = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f768de39-e498-456a-97da-e9fdfdcee670",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imputing missing values with median\n",
    "billing['days_to_pay'] = billing['days_to_pay'].fillna(billing['days_to_pay'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e8904b37-1a94-4f1d-a557-39a5d2d76051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "claim_id          0\n",
       "invoice_amount    0\n",
       "paid_status       0\n",
       "days_to_pay       0\n",
       "policy_name       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#chekcing if values have been imputed and anymore missing values exist\n",
    "billing.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "58786113-c7cc-4cde-b57d-7a08337bf8f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Claims = 0 duplicates\n",
      "\n",
      " RTW = 0 duplicates\n",
      "\n",
      " Comp = 0 duplicates\n",
      "\n",
      " Services = 0 duplicates\n",
      "\n",
      " Billing = 0 duplicates\n"
     ]
    }
   ],
   "source": [
    "#check for duplicates\n",
    "for name, df in dataset.items():\n",
    "    no_duplicates = df.duplicated().sum()\n",
    "    print(f'\\n {name} = {no_duplicates} duplicates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e39eab22-4ff3-4086-826e-5d94a38ac51f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3000 entries, 0 to 2999\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype         \n",
      "---  ------       --------------  -----         \n",
      " 0   claim_id     3000 non-null   object        \n",
      " 1   injury_type  3000 non-null   object        \n",
      " 2   injury_date  3000 non-null   datetime64[ns]\n",
      " 3   worker_age   3000 non-null   int64         \n",
      " 4   gender       3000 non-null   object        \n",
      " 5   employer_id  3000 non-null   object        \n",
      "dtypes: datetime64[ns](1), int64(1), object(4)\n",
      "memory usage: 140.8+ KB\n"
     ]
    }
   ],
   "source": [
    "#ensuring dates are parsed correctly \n",
    "claims['injury_date']= pd.to_datetime(claims['injury_date'])\n",
    "claims.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab0988a7-1aaf-4a23-986a-94015c89c591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table:Claims | Text columns :['claim_id', 'injury_type', 'gender', 'employer_id']\n",
      "Table:RTW | Text columns :['claim_id', 'rtw_status', 'company_name', 'job_role']\n",
      "Table:Comp | Text columns :['claim_id']\n",
      "Table:Services | Text columns :['claim_id', 'service_category', 'service_name', 'provider']\n",
      "Table:Billing | Text columns :['claim_id', 'paid_status', 'policy_name']\n"
     ]
    }
   ],
   "source": [
    "#standardise all text in the dictionary \n",
    "#finding the column with text\n",
    "for name, df in dataset.items():\n",
    "    text_columns = df.select_dtypes(include=['object']).columns.tolist()\n",
    "    print(f'Table:{name} | Text columns :{text_columns}')\n",
    "\n",
    "    #stripping the extra spaces\n",
    "    for col in text_columns: \n",
    "        dataset[name][col] = dataset[name][col].astype(str).str.strip()\n",
    "\n",
    "        #not chaning the claim id\n",
    "        if 'id' not in col.lower():\n",
    "            dataset[name][col] = dataset[name][col].str.title()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "66c4f5de-acd6-4def-8fa0-e9a88ba4e791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Paid' 'Overdue' 'Unpaid']\n"
     ]
    }
   ],
   "source": [
    "print(dataset['Billing']['paid_status'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b5772dd-8be0-486b-8a8e-32ecff8f7635",
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'cleaned_claims.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#saving the cleaned sheets so we can use them for EDA and analysis\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m claims\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcleaned_claims.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m rtw\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcleaned_rtw.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      4\u001b[0m comp\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcleaned_comp.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\conda4\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\conda4\\Lib\\site-packages\\pandas\\core\\generic.py:3967\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3956\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3958\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3959\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3960\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3964\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3965\u001b[0m )\n\u001b[1;32m-> 3967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[38;5;241m.\u001b[39mto_csv(\n\u001b[0;32m   3968\u001b[0m     path_or_buf,\n\u001b[0;32m   3969\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   3970\u001b[0m     sep\u001b[38;5;241m=\u001b[39msep,\n\u001b[0;32m   3971\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m   3972\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m   3973\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[0;32m   3974\u001b[0m     quoting\u001b[38;5;241m=\u001b[39mquoting,\n\u001b[0;32m   3975\u001b[0m     columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   3976\u001b[0m     index_label\u001b[38;5;241m=\u001b[39mindex_label,\n\u001b[0;32m   3977\u001b[0m     mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[0;32m   3978\u001b[0m     chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[0;32m   3979\u001b[0m     quotechar\u001b[38;5;241m=\u001b[39mquotechar,\n\u001b[0;32m   3980\u001b[0m     date_format\u001b[38;5;241m=\u001b[39mdate_format,\n\u001b[0;32m   3981\u001b[0m     doublequote\u001b[38;5;241m=\u001b[39mdoublequote,\n\u001b[0;32m   3982\u001b[0m     escapechar\u001b[38;5;241m=\u001b[39mescapechar,\n\u001b[0;32m   3983\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m   3984\u001b[0m )\n",
      "File \u001b[1;32m~\\conda4\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1013\u001b[0m )\n\u001b[1;32m-> 1014\u001b[0m csv_formatter\u001b[38;5;241m.\u001b[39msave()\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32m~\\conda4\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:251\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[0;32m    252\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath_or_buffer,\n\u001b[0;32m    253\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    254\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    255\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merrors,\n\u001b[0;32m    256\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression,\n\u001b[0;32m    257\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage_options,\n\u001b[0;32m    258\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    268\u001b[0m     )\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[1;32m~\\conda4\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'cleaned_claims.csv'"
     ]
    }
   ],
   "source": [
    "#saving the cleaned sheets so we can use them for EDA and analysis\n",
    "claims.to_csv('cleaned_claims.csv', index= False)\n",
    "rtw.to_csv('cleaned_rtw.csv', index= False)\n",
    "comp.to_csv('cleaned_comp.csv', index = False)\n",
    "services.to_csv('cleaned_services.csv', index = False)\n",
    "billing.to_csv('cleaned_billing.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7d0af9-0b92-4920-aae9-ea5cf1cced81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eee3a2a-bda1-48fc-a30b-a94b2fa2eae2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c7133d-405a-43ca-9c75-368c38f9a9bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6989c6-235b-4de7-9343-96393ba2f7f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
